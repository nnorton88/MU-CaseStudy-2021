{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Carpentry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through the process of ingesting the raw data, renaming columns to human-readable values, adding a couple of flags to be used later, and categorizing responses in logical groupings.\n",
    "\n",
    "Source of data:\n",
    "\n",
    "https://www.icpsr.umich.edu/web/ICPSR/studies/37023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Initial data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers ingesting the data, renaming the columns, dropping unnecessary/unused columns, and adding a couple of useful flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pwd, os\n",
    "\n",
    "path= '/dsa/groups/casestudy2021su/group_3'\n",
    "\n",
    "# We have a CSV file that translates the study's variable names (Q1, Q2, etc) into easier-to-understand terms\n",
    "# Here we create a mapper dict that holds the translations\n",
    "# cnames = pd.read_csv (f'{path}/ColNames.csv')\n",
    "\n",
    "cnames = pd.read_csv (f'{path}/ColNames.csv', sep =',')\n",
    "\n",
    "colNames = dict(zip(cnames.to_dict('list')['Var Name'], cnames.to_dict('list')['DF Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data\n",
    "data = pd.read_table (f'{path}/37023-0003-Data.tsv', engine='python') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename using mapper dict\n",
    "data=data.rename (mapper=colNames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns not in colNames mapper\n",
    "data = data.drop(data.columns.difference(colNames.values()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flag indicating if respondent was eligible to vote (based on age)\n",
    "\n",
    "data['eligibleToVote'] = data['age'].map(lambda x: 1 if x >= 18 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Voted binary variable\n",
    "data['Voted'] = data['pyVoted'].map(lambda x: 1 if x >= 2 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Grouping & Categorizing responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections below I will be 'grouping' numeric responses within the dataset into more easy to understand categories as determined by the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to group responses into named categories\n",
    "def groupResponses (df, cols, mapperDict, naVal = [], naCat = 'N/A'):\n",
    "    \"\"\" \n",
    "    Groups responses into categories based on the mapperDict\n",
    "    @ params:\n",
    "        df                      - required    : dataframe with columns to be mapped\n",
    "        cols                    - required    : dictionary containing one or more columns that the groupings apply to along\n",
    "            with the name of the new column to hold the grouping names as {old: new}.\n",
    "        mapperDict              - required    : Dictionary containing mapping definition as response: categoryName.  \n",
    "            Should be defined such that each key is an integer representing the greatest value for that categoryName. \n",
    "            For example, if values of 1 - 2 should be categorized as \"neg\", the dictionary should contain 2: 'neg'\n",
    "            The dictionary doesn't need to be in any particular order\n",
    "        naVal                   - optional    : Response value(s) (as a list) that should be categorized as \"N/A\"\n",
    "            If this is specified, only the values in the naVal list will be categorized as \"N/A\"\n",
    "            Otherwise, all values not mapped in the mapperDict will be categorized as \"N/A\"\n",
    "        naCat                   - optional    : Label for the N/A Category.  Default is \"N/A\"\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    prevVal = None\n",
    "    mDict = {}\n",
    "    # First we go through the mapperDict in order by key and fill in the blanks so all values are accounted for\n",
    "    for key in sorted (mapperDict.keys()):\n",
    "        if prevVal is None:\n",
    "            rng = range (key+1)\n",
    "        else:\n",
    "            rng = range (prevVal, key+1)\n",
    "    \n",
    "        for i in rng:\n",
    "            mDict [i] = mapperDict[key]\n",
    "    \n",
    "        prevVal = key + 1\n",
    "    \n",
    "    # Add the specified naVals (if any) to the mapperDict\n",
    "    for val in naVal:\n",
    "        mDict[val] = naCat\n",
    "    \n",
    "    # Create a new grouped column based on mapping the values from the mapper dict.\n",
    "    # Some values are strings (objects), and some are just ints. So we do some casting to int to make sure the mapping works.\n",
    "    for oldCol, newCol in cols.items():\n",
    "        df[newCol] = df[oldCol].map(lambda x: mDict[int(x)] if (type(x) == int or x.isdigit()) and int(x) in mDict.keys() else naCat)\n",
    "\n",
    "    # If no naVals were specified, fill in everything not covered by the mapperDict (which would now be NaN) with the specified\n",
    "    # naCat value.\n",
    "    if not (naVal):\n",
    "        for newCol in cols.values():\n",
    "            df[newCol] = df[newCol].fillna(naCat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1/2- neg, 3- neutral, 4/5- post, 99 - NA\n",
    "\n",
    "UGcols = ['politicsInfluenceSelf',\n",
    "        'politicsInfluenceLocal',\n",
    "        'politicsFunImportance',\n",
    "        'politicsEngagementOccassional',\n",
    "        'politicsInvovledOnlyImportant',\n",
    "        'peopleTrusted',\n",
    "        'peopleTakeAdvantage',\n",
    "        'peopleFair',\n",
    "        'newsUnbiased',\n",
    "        'newsAccurate',\n",
    "        'newsTrustworthy',\n",
    "        'selfUnderstandPolitics',\n",
    "        'selfMoreInvolvedPolitics',\n",
    "        'selfPoliticsTooComplicated',\n",
    "        'selfInternetFindPoliticalInfo',\n",
    "        'selfInternetDiscussPolitics',\n",
    "        'selfInternetExpressConcern',\n",
    "        'govtHelpVulnerable',\n",
    "        'govtBusinessRegulation',\n",
    "        'govtPoorDependence',\n",
    "        'immigrationThreatenTradValues',\n",
    "        'gayMarriage',\n",
    "        'abortionLegal',\n",
    "        'protestNormal',\n",
    "        'protestEffective',\n",
    "        'protestNotRepresentative',\n",
    "        'protestIllegal']\n",
    "\n",
    "cols = {col: col+'_Groups' for col in UGcols}\n",
    "\n",
    "# For these columns, 1-2 = neg, 3 = neutral, and 5 = pos\n",
    "groups = {2: 'neg', 3: 'neutral', 5: 'pos'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols, \n",
    "                mapperDict = groups,  \n",
    "                naVal = [99],  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1- neg, 2/3/4- pos\n",
    "UGcols1 = ['pyRaisedMoneyForCharity',\n",
    "        'pyDonatedMoneyForCause',\n",
    "        'pySignedUpForCauseInfo',\n",
    "        'pyContacedPolitican',\n",
    "        'pyCommentedNews',\n",
    "        'pyVoted',\n",
    "        'pyEncourageVote',\n",
    "        'pyDisplayedCauseSymbol',\n",
    "        'pyBoughtForCause',\n",
    "        'pyBoycottedForCause',\n",
    "        'pySignedPetition',\n",
    "        'pyAttendedRally',\n",
    "        'pyDiscussedPoliticsFriendsFamily']\n",
    "\n",
    "cols1 = {col: col+'_Groups' for col in UGcols1}\n",
    "\n",
    " # For these columns, 1 = neg, 2/3/4 = pos\n",
    "groups = {1: 'neg', 4: 'pos'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols1, \n",
    "                mapperDict = groups,  \n",
    "                naVal = [99],  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1/2/3- pos, 4- neg, 9- n/a\n",
    "\n",
    "UGcols2 = ['videoGamePlayingGamer',\n",
    "         'videoGamePlayingHelpOthers',\n",
    "         'videoGamePlayingLearnSocietyProblems',\n",
    "         'videoGamePlayingMoralEthicalIssues']\n",
    "\n",
    "cols2 = {col: col+'_Groups' for col in UGcols2}\n",
    "\n",
    " # For these columns, 1/2/3 = pos, 4 = neg, 9 = n/a\n",
    "groups2 = {3: 'pos', 4: 'neg', 9: 'NotMe'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols2, \n",
    "                mapperDict = groups2,\n",
    "                naVal = [99],\n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1/2- pos, 3- neg\n",
    "UGcols3 = ['groupPoliticalIssueInternetRole',\n",
    "         'groupSocialIssueInternetRole',\n",
    "         'groupLocalCommunityInternetRole',\n",
    "         'groupPoliticanInternetRole',\n",
    "         'groupElectionCampaignInternetRole',\n",
    "         'internetUseSearchEngine',\n",
    "         'internetUseVideos',\n",
    "         'internetUseTVShows',\n",
    "         'internetUseBoughtThings',\n",
    "         'internetUseTravel',\n",
    "         'internetUseHealthStandard',\n",
    "         'internetUseHealthDifficult',\n",
    "         'internetUseSocialNetwork',\n",
    "         'internetUseShareOwnWork',\n",
    "         'internetUseShareOtherWork',\n",
    "         'internetUseRemixFoundWork',\n",
    "         'internetUsePayFine',\n",
    "         'internetUseGovernmentBenefits',\n",
    "         'internetUseGovernmentForms']\n",
    "\n",
    "cols3 = {col: col+'_Groups' for col in UGcols3}\n",
    "\n",
    " # For these columns, 1/2 = pos, 3 = neg\n",
    "groups = {2: 'pos', 3: 'neg'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols3, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- currently in high school, 2- did not complete, etc.\n",
    "\n",
    "UGcols4 = ['USAEducation']\n",
    "\n",
    "cols4 = {col: col+'_Groups' for col in UGcols4}\n",
    "\n",
    " # For these columns, 1 = InHighSchool, 2 = HighSchool, 3 = SomeCollege, 4 = 2YearCollege,\n",
    " # 5 = 4YearCollege , 6 = Masters , 7 = Doctoral , 8 = Professional(JD/MD) , 9 = Other,\n",
    " # 99 = IDK   \n",
    "    \n",
    "groups = {1: 'InHighSchool', 2: 'HighSchoolGrad', 3:'NotHighSchoolGrad', 4:'SomeCollege',\n",
    "          5:'2YearCollege',6:'4YearCollege',7:'Masters',8:'Doctoral',\n",
    "          9:'Professional(JD/MD)',10: 'Other',99: 'IDK'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols4, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- democrat, 2- republican, 3- independent, 4- something else, 5- none, 99- don't know\n",
    "\n",
    "\n",
    "UGcols5 = ['USAPoliticalParty']\n",
    "\n",
    "cols5 = {col: col+'_Groups' for col in UGcols5}\n",
    "\n",
    " # For these columns, 1 = Dem, 2 = Rep, 3 = Ind, 4 = SomethingElse,\n",
    " # 5 = None, 99 = IDK   \n",
    "    \n",
    "groups = {1: 'Dem', 2: 'Rep', 3:'Ind', 4:'SomethingElse',5:'None', 99: 'IDK'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols5, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1/2- neg, 3/4- pos\n",
    "UGcols6 = ['localNewsInterest',\n",
    "           'nationalNewsInterest',\n",
    "           'politicalNewsInterest',\n",
    "           'internationalNewsInterest',\n",
    "           'facebookLearnEvents',\n",
    "           'facebookFollowPoliticalLinks',\n",
    "           'facebookLearnEventsBeforeNews',\n",
    "           'facebookLearnEventsDeeper',\n",
    "           'facebookLearnOpposingViewpoints',\n",
    "           'facebookPostPoliticalLinks',\n",
    "           'facebookPostPoliticalOpinions',\n",
    "           'facebookEncouragePoliticalAction',\n",
    "           'facebookEncourageVote',\n",
    "           'facebookRepostPoliticalMaterial',\n",
    "           'facebookLikePoliticalMaterial',\n",
    "           'twitterUseReadNewsPolitics',\n",
    "           'twitterUseShareNewsPolitics',\n",
    "           'twitterUseDiscussNewsPolitics']\n",
    "\n",
    "cols6 = {col: col+'_Groups' for col in UGcols6}\n",
    "\n",
    " # For these columns, 1/2 = neg, 3 = pos\n",
    "groups = {2: 'neg', 4: 'pos'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols6, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1/2- neg, 3/4- pos, 9- n/a\n",
    "UGcols7 = ['USAPoliticalNewsCableTV',\n",
    "           'USAPoliticalNewsSourceRadio',\n",
    "           'USAPoliticalNewsSourceDailyNewspapers',\n",
    "           'USAPoliticalNewsSourceWeeklyMagazines',\n",
    "           'USAPoliticalNewsSourceNetworkTV',\n",
    "           'USAPoliticalNewsSourceLocalTV',\n",
    "           'USAPoliticalNewsSourceLateNightTV',\n",
    "           'USAPoliticalNewsSourceComedyTV',\n",
    "           'USAPoliticalNewsSourceSocialMedia']\n",
    "\n",
    "cols7 = {col: col+'_Groups' for col in UGcols7}\n",
    "\n",
    " # For these columns, 1/2 = neg, 3/4 = pos, 9 = Never\n",
    "groups = {2: 'neg', 4: 'pos', 9: 'never'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols7, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1- No Interest, 2/3 - LowInterest, 4/5 - High Interest\n",
    "\n",
    "UGcols8 = ['politicalInterest']\n",
    "\n",
    "cols8 = {col: col+'_Groups' for col in UGcols8}\n",
    "\n",
    " # For these columns, 1 = NoInterest, 2/3  = LowInterest\n",
    " # 4/5 = HighInterest\n",
    "groups2 = {1: 'NoInterest', 3: 'LowInterest', 5: 'HighInterest'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols8, \n",
    "                mapperDict = groups2,\n",
    "                naVal = [99],\n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1- multi-player, 2- co-operative, 3- single-player\n",
    "\n",
    "UGcols9 = ['videoGameTypeMostFrequent']\n",
    "\n",
    "cols9 = {col: col+'_Groups' for col in UGcols9}\n",
    "\n",
    " # For these columns, 1 = NoInterest, 2/3  = LowInterest\n",
    " # 4/5 = HighInterest\n",
    "groups2 = {1: 'multi-player', 3: 'co-operative', 5: 'single-player'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols9, \n",
    "                mapperDict = groups2,\n",
    "                naVal = [99],\n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic = 1/2- neg, 3- neutral, 4/5- post, 9- IDK\n",
    "\n",
    "UGcols10 = ['facebookLearnOthersInterests',\n",
    "            'facebookUnderstandSociety',\n",
    "            'facebookDailyRoutine',\n",
    "            'facebookOutOfTouchIfNotUsed',\n",
    "            'facebookUpsetIfShutdown']\n",
    "\n",
    "cols10 = {col: col+'_Groups' for col in UGcols10}\n",
    "\n",
    "# For these columns, 1-2 = neg, 3 = neutral, 5 = pos, 9 = IDK\n",
    "groups = {2: 'neg', 3: 'neutral', 5: 'pos', 9: 'IDK'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols10, \n",
    "                mapperDict = groups,  \n",
    "                naVal = [99],  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- Never, 2- <1PerMonth, etc.\n",
    "\n",
    "\n",
    "UGcols11 = ['socialMediaUseFacebook',\n",
    "            'socialMediaUseTwitter',\n",
    "            'socialMediaUseLinkedIn',\n",
    "            'socialMediaUseYouTube',\n",
    "            'socialMediaUseInstagram',\n",
    "            'socialMediaUsePinterest',\n",
    "            'socialMediaUseMyspace',\n",
    "            'socialMediaUseGooglePlus',\n",
    "            'socialMediaUseFoursquare',\n",
    "            'socialMediaUseReddit',\n",
    "            'videoGameUseFrequency']\n",
    "\n",
    "cols11 = {col: col+'_Groups' for col in UGcols11}\n",
    "\n",
    " # For these columns, 1 = Never, 2 = <1PerMonth, 3 = 1PerMonth, 4 = 2-3MPeronth,\n",
    " # 5 = 1PerWeek , 6 = 2-3PerWeek , 7 = Daily , 8 = MultipleTimesPerDay \n",
    "    \n",
    "groups = {1: 'Never', 2: '<1PerMonth', 3:'1PerMonth',\n",
    "          4:'2-3PerMonth',5:'1PerWeek',6:'2-3PerWeek',7:'Daily',\n",
    "          8:'MultipleTimesPerDay'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols11, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- NotInLastWeek, 2- <10Minutes, etc.\n",
    "\n",
    "\n",
    "UGcols12 = ['facebookUseAmount',\n",
    "            'twitterUseAmount']\n",
    "\n",
    "cols12 = {col: col+'_Groups' for col in UGcols12}\n",
    "\n",
    " # For these columns, 1 = NotInLastWeek, 2 = <10Minutes, 3 = 10-30Minutes,\n",
    " # 4 = 31-60Minutes, 5 = 61-90Minutes , 6 = >90Minutes \n",
    "    \n",
    "groups = {1: 'NotInLastWeek', 2: '<10Minutes', 3:'10-30Minutes',\n",
    "          4:'31-60Minutes',5:'61-90Minutes',6:'>90Minutes'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols12, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1/2- LowConfidence, 3/4 - HighConfidence, 99 - IDK\n",
    "\n",
    "\n",
    "UGcols13 = ['politiciansDoRight',\n",
    "            'politiciansCountryBestInterests',\n",
    "            'politiciansTellTruth']\n",
    "\n",
    "cols13 = {col: col+'_Groups' for col in UGcols13}\n",
    "\n",
    " # For these columns, 1 = NotInLastWeek, 2 = <10Minutes, 3 = 10-30Minutes,\n",
    " # 4 = 31-60Minutes, 5 = 61-90Minutes , 6 = >90Minutes  \n",
    "    \n",
    "groups = {2: 'LowConfidence', 4: 'HighConfidence', 99:'IDK'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols13, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- EveryDay, 2- 3-4Week, etc.\n",
    "\n",
    "\n",
    "UGcols14 = ['discussPoliticsFriends',\n",
    "            'discussPoliticsFamily',\n",
    "            'discussPoliticsOthers']\n",
    "\n",
    "cols14 = {col: col+'_Groups' for col in UGcols14}\n",
    "\n",
    " # For these columns, 1 = EveryDay, 2 = 3-4PerWeek, 3 = 1-2PerWeek, \n",
    " # 4 = 1-2PerMonth, 5 = Rarely , 6 = Never  \n",
    "    \n",
    "groups = {1: 'EveryDay', 2: '3-4PerWeek', 3:'1-2PerWeek',\n",
    "          4:'1-2PerMonth',5:'Rarely',6:'Never'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols14, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- City, 2-Suburban, 3-SmallTown, 4-Rural\n",
    "\n",
    "\n",
    "UGcols15 = ['USAAreaType']\n",
    "\n",
    "cols15 = {col: col+'_Groups' for col in UGcols15}\n",
    "\n",
    " # For these columns, 1 = City, 2 = Suburban, 3 = SmallTown, 4 = Rural  \n",
    "    \n",
    "groups = {1: 'City', 2: 'Suburban', 3:'SmallTown',4:'Rural'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols15, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- Male, 2-Female\n",
    "\n",
    "\n",
    "UGcols16 = ['gender']\n",
    "\n",
    "cols16 = {col: col+'_Groups' for col in UGcols16}\n",
    "\n",
    " # For these columns, 1 = Male, 2 = Female\n",
    "    \n",
    "groups = {1: 'Male', 2: 'Female'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols16, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1 = Other, 2 = English, 99 = WontSay\n",
    "\n",
    "\n",
    "UGcols17 = ['langSpokenHome']\n",
    "\n",
    "cols17 = {col: col+'_Groups' for col in UGcols17}\n",
    "\n",
    " # For these columns, 1 = Other, 2 = English, 99 = WontSay\n",
    "    \n",
    "groups = {1: 'Other', 2: 'English', 99: 'WontSay'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols17, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1-Cafe/Kiosk,2-Library,3-Home, etc\n",
    "\n",
    "\n",
    "UGcols18 = ['internetAccessSetting']\n",
    "\n",
    "cols18 = {col: col+'_Groups' for col in UGcols18}\n",
    "\n",
    " # For these columns, 1 = Other, 2 = English, 99 = WontSay\n",
    "    \n",
    "groups = {1: 'Cafe/Kiosk', 2: 'Library', 3: 'Home', 4: 'OthersHome',\n",
    "          5: 'Work',6:'School',7:'MobilePhone',8:'Laptop',9:'Other'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols18, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SPECIAL CASE NOTE: The following columns would normally be bool columns.\n",
    "###However, many of the responses in this columns are NaN which needs to be corrected\n",
    "###This is because these questions where conditional, that is they were only asked if \n",
    "###the respondent answered in the affirmative on the previous question, others it was left blank\n",
    "\n",
    "# Selection of columns whose responses can all be grouped using the same range of values\n",
    "# Grouping Logic : 1- Yes, 2-No (remainder will be NA)\n",
    "\n",
    "\n",
    "UGcols19 = ['videoGameTypeMultiplayerPVP','videoGameTypeMultiplayerCoop','videoGameTypeSingleplayer',\n",
    "   'groupFocusLocal','groupFocusNational','groupFocusInternational']\n",
    "\n",
    "cols19 = {col: col+'_Groups' for col in UGcols19}\n",
    "\n",
    " # For these columns, Nick: 1- Yes, 2-No (remainder will be NA)\n",
    "    \n",
    "groups = {1: 'Yes', 2: 'No', 99: 'WontSay'}\n",
    "\n",
    "groupResponses (df = data, \n",
    "                cols = cols19, \n",
    "                mapperDict = groups,  \n",
    "                naCat = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists Ungrouped column headers for removal\n",
    "UnGroupedcolumns = UGcols+UGcols1+UGcols2+UGcols3+UGcols4+UGcols5+UGcols6+UGcols7+UGcols8+UGcols9+UGcols10+UGcols11+UGcols12+UGcols13+UGcols14+UGcols15+UGcols16+UGcols17+UGcols18+UGcols19\n",
    "Groupedcolumns= [col+'_Groups' for col in UnGroupedcolumns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III - Slicing data into separate data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the responses, we're going to produce a few different dataframes that slice the data in different ways.  Each one has a specific role to play in our future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame with Grouped columns removing ungrouped columns\n",
    "Groupeddata=data.drop(UnGroupedcolumns, axis=1)\n",
    "#utilize Vote eligible flag to remove those under 18 from dataset\n",
    "# Note that this only removes 3 observations\n",
    "Groupeddata=Groupeddata[Groupeddata['eligibleToVote']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# for dumping \n",
    "joblib.dump(Groupeddata, 'Groupeddata.pkl')\n",
    "\n",
    "# for loading\n",
    "#commented out to ensure object is not overwritten\n",
    "###data = joblib.load('Groupeddata.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I am creating lists to eliminate unusable variables for later predictive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Note expand column names\n",
    "\n",
    "#function for determining the difference between two lists\n",
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif\n",
    "\n",
    "#First,create a list of current columns in the grouped data set\n",
    "currentcolumns=Groupeddata.columns.tolist()\n",
    "\n",
    "#Second, create a list of Grouped column header names using the previously created\n",
    "#Ungroupedcolumns list used to remove ungrouped columns from the origional dataset\n",
    "\n",
    "Groupedcolumns= [col+'_Groups' for col in UnGroupedcolumns]\n",
    "\n",
    "#Using the currentcolumns list and the Groupedcolumns list\n",
    "#I will use the Diff() function to create a list of columns not contained in.\n",
    "#eg a list of the current columns with no groupedcolumns\n",
    "\n",
    "noGroupedcolumns1=Diff(currentcolumns,Groupedcolumns)\n",
    "\n",
    "#Items created with diff function needs to be converted to a str for later use\n",
    "noGroupedcolumns=[str(e) for e in noGroupedcolumns1]\n",
    "\n",
    "#Since we are focusing on the US respondents, I'll need to remove columns\n",
    "#relating to the UK and AUS.\n",
    "#This list containing sub strings to search for within the headings of thos columns\n",
    "foreigncolumns = ['UK','AUS']\n",
    "\n",
    "#Isolate columns for UK and AUS for removal\n",
    "foreigncolumns=[ele for ele in noGroupedcolumns for x in foreigncolumns if x in ele]\n",
    "\n",
    "#remove UK and AUS columns\n",
    "noGroupedForeigncolumns1=Diff(noGroupedcolumns,foreigncolumns)\n",
    "\n",
    "\n",
    "#again, convert items to str\n",
    "noGroupedForeigncolumns=[str(e) for e in noGroupedForeigncolumns1]\n",
    "\n",
    "\n",
    "#After reviewing each of the remaining columns, I have marked\n",
    "# the following for removal\n",
    "#For context, each of these is manual entry and not suitable for predictive\n",
    "#Analysis with out significant transformation and assumption about the intended response\n",
    "manualentrycolumns =['politicalSocialIssue1', 'politicalSocialIssue2', \n",
    "                     'politicalSocialIssue3','USAPoliticalPartyOther',\n",
    "                     'langSpokenHomeOther','USAOtherEthnicityOther',\n",
    "                     'USAEducationOther','internetAccessOther',\n",
    "                     'internetAccessSettingOther']\n",
    "\n",
    "#remove manual entry/non-binary columns, leaving only binary columns\n",
    "binarycolumns1=Diff(noGroupedForeigncolumns,manualentrycolumns)\n",
    "\n",
    "#again, convert items to str\n",
    "binarycolumns=[str(e) for e in binarycolumns1]\n",
    "\n",
    "#combine remaining binary columns and grouped columns\n",
    "\n",
    "finalcolumns=binarycolumns+Groupedcolumns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(finalcolumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for One Hot Encoding\n",
    "#DF contains only either binary or Grouped data for one-hot/dummy encoding\n",
    "OneHotdata=Groupeddata[finalcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical variables to categorical\n",
    "OneHotdata[Groupedcolumns]=OneHotdata[Groupedcolumns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Binary Variables to Bool\n",
    "\n",
    "#Age is the only non-binary variable remaining in binarycolumns list so\n",
    "#will need to create a list without it\n",
    "\n",
    "noAgebinarycolumns=['internetAccessCafeKiosk','internetAccessLibrary',\n",
    "                    'internetAccessOwnHome','internetAccessOtherHome',\n",
    "                    'internetAccessWork','internetAccessSchool',\n",
    "                    'internetAccessMobilePhone','internetAccessLaptopTablet',\n",
    "                    'internetAccessSomewhereElse','internetAccessNone',\n",
    "                    'groupPoliticalIssue','groupSocialIssue',\n",
    "                    'groupLocalCommunity','groupPolitican',\n",
    "                    'groupElectionCampaign','USAAsianPacificIslander',\n",
    "                    'USABlack','USAWhite','USAHispanic','USALatino',\n",
    "                    'USAMiddleEastern','USAOtherEthnicity','eligibleToVote',\n",
    "                    'Voted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert remaining columns to bool\n",
    "# Note: depending on the version of Pandas in the container, you may need to do astype('Bool') instead of astype('boolean')\n",
    "# OneHotdata[noAgebinarycolumns]=OneHotdata[noAgebinarycolumns].astype('Bool')\n",
    "OneHotdata[noAgebinarycolumns]=OneHotdata[noAgebinarycolumns].astype('boolean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# for dumping \n",
    "joblib.dump(OneHotdata, 'OneHotdata.pkl')\n",
    "\n",
    "# for loading\n",
    "#OneHotdata = joblib.load('OneHotdata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will need for one-hot encoding\n",
    "import joblib\n",
    "\n",
    "# for dumping \n",
    "joblib.dump([Groupedcolumns], 'Groupedcolumns.pkl')\n",
    "\n",
    "# for loading\n",
    "#OHcolumns = joblib.load('Groupedcolumns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
